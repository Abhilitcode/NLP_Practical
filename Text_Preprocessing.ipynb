{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWj2xHQiiLSGnV0MwM5wBa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhilitcode/NLP_Practical/blob/main/Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOPIC -: TEXT PRE-PROCESSING\n",
        "Introduction-:\n",
        "IN this we will undestand what all pre-processig techniques we used once we collect the data.\n",
        "Text pre..... - is of 2 types basic and advanced.\n",
        "\n",
        "1) basic we will see here and advanced includes topics such as pos tagging, chunking, parsing, coreference resolution."
      ],
      "metadata": {
        "id": "UsFvJKNMCaXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOWERCASING-: Python is a case sensitive language. when two words are almost same exept the first characters. ex-: Basically and basically so here it becomnes difficult for tokenizer to understand both words are same to avoid this we lower case everyhting."
      ],
      "metadata": {
        "id": "1hjOd54TE7MF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "v70jK00KCZJT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/sample_data/IMDB Dataset.csv\")"
      ],
      "metadata": {
        "id": "7_5qIKgcG6wO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFoeOB5gJnVU",
        "outputId": "a2e8df59-1c0c-4348-a66c-5bc033c9aa80"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YVJIrf0lJowy",
        "outputId": "d27c60e4-ad67-4510-d6f6-4b70101b954b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb93a78d-4002-4c38-908d-5b78a226b379\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb93a78d-4002-4c38-908d-5b78a226b379')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb93a78d-4002-4c38-908d-5b78a226b379 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb93a78d-4002-4c38-908d-5b78a226b379');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb4dd72e-0612-474e-a4d7-b088694ccde1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb4dd72e-0612-474e-a4d7-b088694ccde1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb4dd72e-0612-474e-a4d7-b088694ccde1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "8-rjYASXJtQq",
        "outputId": "48181fe9-6a0d-4b45-bed0-66cd71c8810b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'][3].lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "Kjnq0qzSJy7a",
        "outputId": "b7791638-1c82-4071-80cb-87129302d2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if i had to convert all string to lower thn use str.lower()"
      ],
      "metadata": {
        "id": "IykpGvypJ8yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'] = data['review'].str.lower()"
      ],
      "metadata": {
        "id": "kP63Ck6OJ4-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['review']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "se_SxK4uKI2i",
        "outputId": "4eb386ac-062c-47f2-d470-740323672ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        one of the other reviewers has mentioned that ...\n",
              "1        a wonderful little production. <br /><br />the...\n",
              "2        i thought this was a wonderful way to spend ti...\n",
              "3        basically there's a family where a little boy ...\n",
              "4        petter mattei's \"love in the time of money\" is...\n",
              "                               ...                        \n",
              "49995    i thought this movie did a down right good job...\n",
              "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
              "49997    i am a catholic taught in parochial elementary...\n",
              "49998    i'm going to have to disagree with the previou...\n",
              "49999    no one expects the star trek movies to be high...\n",
              "Name: review, Length: 50000, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i thought this was a wonderful way to spend ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically there's a family where a little boy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>i thought this movie did a down right good job...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>i am a catholic taught in parochial elementary...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>i'm going to have to disagree with the previou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>no one expects the star trek movies to be high...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so lowercasing is genrally the first pre-processig  step."
      ],
      "metadata": {
        "id": "LwKCOxrMKcqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step in pre-processing is to remove the unnecessary words. which are called as HTML-Tags. so whenevr we collect the data it usually have html tags to remove them is imp. bcuz in nlp tasks its not much necessaary of these tags . the use of these tags are mostly to display things on browser."
      ],
      "metadata": {
        "id": "YoE63VM6KjJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so this imdb data is also scrapped from a website so we will remove the html tages from them."
      ],
      "metadata": {
        "id": "EF00vXUCMQp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "-Ux8jxptKMy6",
        "outputId": "460afcb3-f5a4-44f2-9081-a423351f0278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using regex we will remove this html tags such as <br> etc."
      ],
      "metadata": {
        "id": "ckYR3GAfMcZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will create a function that will remove all html tags from the sentence."
      ],
      "metadata": {
        "id": "ZqFZuc6nMui7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "<div class=\"intro\">\n",
        "  <p>Welcome to our <span style=\"font-weight:bold;\">online platform</span>! We are excited to bring you <a href=\"https://example.com\" target=\"_blank\">innovative solutions</a> for your daily needs. Our website offers a <em>wide range</em> of products, including <strong>electronics</strong>, <strong>home appliances</strong>, and <strong>fashion accessories</strong>.</p>\n",
        "</div>\n",
        "<div>\n",
        "  <p>Our <i>mission</i> is to provide quality service at affordable prices. By subscribing to our <span class=\"newsletter\">newsletter</span>, you’ll receive <u>exclusive</u> deals and updates. Don’t miss out on our <mark>special offers</mark> and <a href=\"https://deals.example.com\">discounts</a> throughout the year. Our dedicated <span style=\"color:blue;\">customer support</span> team is always here to assist you.</p>\n",
        "</div>\n",
        "<p>Thank you for choosing us. We hope you enjoy a seamless shopping experience on our platform. Happy shopping!</p>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "q7txiGHWPT37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In regular expressions, `.*?` is a non-greedy (or \"lazy\") match. This means it will match as few characters as possible while still satisfying the overall pattern. In the context of HTML tag removal, this is useful because it helps the pattern stop at the first closing `>`, even if there are other `>` characters later in the string.\n",
        "\n",
        "### Example\n",
        "\n",
        "Consider the following HTML snippet:\n",
        "\n",
        "```html\n",
        "\"<div>This is <span>some text</span> inside a div</div>\"\n",
        "```\n",
        "\n",
        "#### With Greedy Matching (`.*`)\n",
        "\n",
        "If we use `.*` (a greedy match), the expression `<.*>` will try to match as much of the string as possible. Here’s what happens:\n",
        "\n",
        "- `<.*>`: This pattern starts matching at the first `<` and keeps matching until it reaches the **last** `>`.\n",
        "- So, `<.*>` matches:\n",
        "  ```\n",
        "  \"<div>This is <span>some text</span> inside a div</div>\"\n",
        "  ```\n",
        "\n",
        "This result is incorrect because we wanted to match each tag individually (like `<div>`, `<span>`, and `</span>`), not the entire string from the first `<` to the last `>`.\n",
        "\n",
        "#### With Non-Greedy Matching (`.*?`)\n",
        "\n",
        "With non-greedy matching, `.*?` will match as little as possible while still satisfying the pattern `<.*?>`. Here’s how it behaves:\n",
        "\n",
        "- `<.*?>`: This pattern starts matching at the first `<` and **stops as soon as it encounters the first `>`** after that.\n",
        "- Using `<.*?>` on the string `\"<div>This is <span>some text</span> inside a div</div>\"` will match:\n",
        "  - `<div>` (the first `<` to the first `>`)\n",
        "  - `<span>` (the next `<` to the next `>`)\n",
        "  - `</span>` (the following `<` to the next `>`)\n",
        "  - `</div>` (the final `<` to the last `>`)\n",
        "\n",
        "So, with `.*?`, each HTML tag is matched individually, which allows us to remove them one by one without unintentionally capturing too much text.\n",
        "\n",
        "### Why `.*?` Works for Removing HTML Tags\n",
        "\n",
        "By using the non-greedy `.*?`, we ensure that only one tag at a time is matched and removed. If we used `.*`, it might remove large portions of the text between the first and last tags, which is usually not what we want when cleaning HTML."
      ],
      "metadata": {
        "id": "qgy4gAaVQgdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_tags(text):\n",
        "    # Pattern to match any HTML tag\n",
        "    pattern = re.compile(r'<.*?>')\n",
        "    # Substitute all matches with an empty string\n",
        "    return pattern.sub('', text)\n"
      ],
      "metadata": {
        "id": "IkZDfa_NMYZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_tags(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "ql-AzHHZQC-K",
        "outputId": "f0efc676-678a-49a1-c758-a78bd43f988c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n  Welcome to our online platform! We are excited to bring you innovative solutions for your daily needs. Our website offers a wide range of products, including electronics, home appliances, and fashion accessories.\\n\\n\\n  Our mission is to provide quality service at affordable prices. By subscribing to our newsletter, you’ll receive exclusive deals and updates. Don’t miss out on our special offers and discounts throughout the year. Our dedicated customer support team is always here to assist you.\\n\\nThank you for choosing us. We hope you enjoy a seamless shopping experience on our platform. Happy shopping!\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets apply this function inside this data set."
      ],
      "metadata": {
        "id": "J1yjuUOCRsZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_tag_removed = data['review'].apply(remove_tags)"
      ],
      "metadata": {
        "id": "0ykYY0bEQGYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "all tags are removed."
      ],
      "metadata": {
        "id": "ydhsHINiShEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_tag_removed[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "ZKChs82SSGGL",
        "outputId": "f206cebb-c0d1-4b52-cb0c-e1b8ddc632eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic - Remove URLS.\n",
        "Sometimes we find urls in text data. suppose ur working on whatsapp chat analysis so at these places u might see that the users have shared the urls in thier chat. so we will try to remove those urls ."
      ],
      "metadata": {
        "id": "wn-0NaQLxZD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = 'Learn more about our services at href=\"http://www.example.com\" Example Site.'\n",
        "\n",
        "text2 = 'For detailed guides, visit htttp=\"https://guide.example.com\" our guides page.'\n",
        "\n",
        "text3 = 'Discover the latest trends on href=\"www.fashion.example.com\" Fashion Hub.'\n",
        "\n",
        "text4 = 'Connect with professionals on htttp=\"https://www.networking.example.com\" our networking platform.'\n"
      ],
      "metadata": {
        "id": "Ygns1_chSRmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "you can learn how to create regular expressions or else you can use stackoverflow to copy paste."
      ],
      "metadata": {
        "id": "loT2SDf7zo3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LM5LyJKhzhy9",
        "outputId": "cae0ce06-a7e6-4583-8914-94bb8e469bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Connect with professionals on htttp=\"https://www.networking.example.com\" our networking platform.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets create a function that automatically removes all the urls from the input and gives you the output."
      ],
      "metadata": {
        "id": "mKcII5yq1W23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of the Regular Expression\n",
        "https?://: Matches http:// or https://. The ? makes the s optional, allowing both http and https.\n",
        "\\S+: Matches any sequence of non-whitespace characters, covering the rest of the URL.\n",
        "|: Acts as an OR operator, allowing for alternative patterns.\n",
        "www\\.\\S+: Matches URLs that start with www. followed by non-whitespace characters\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Explanation of the Updated Regular Expression\n",
        "https?://\\S+: Matches standalone URLs starting with http:// or https://.\n",
        "www\\.\\S+: Matches standalone URLs starting with www..\n",
        "href=\"https?://\\S+\": Matches href attributes with URLs starting with http:// or https:// inside double quotes.\n",
        "href=\"www\\.\\S+\": Matches href attributes with URLs starting with www. inside double quotes"
      ],
      "metadata": {
        "id": "CGlxLFSn6HZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_url(text):\n",
        "    # Pattern to match standalone URLs (http, https, www) and URLs in href attributes\n",
        "    pattern = re.compile(r'https?://\\S+|www\\.\\S+|href=\"https?://\\S+\"|href=\"www\\.\\S+\"')\n",
        "    # Substitute all matches with an empty string\n",
        "    return pattern.sub('', text)"
      ],
      "metadata": {
        "id": "gJ4x99do1Um4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_url(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uflHm1_P3X00",
        "outputId": "e23a3b84-dfa0-4837-81e1-ac76270549c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Learn more about our services at  Example Site.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_url(text2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vRI2CVlC4-kT",
        "outputId": "66020fae-e9fb-4e4e-a79f-72b0e5ea337a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For detailed guides, visit htttp=\" our guides page.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_url(text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "r9T803SV5AYf",
        "outputId": "e17729d4-3d89-4d03-b47e-094cf442bc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Discover the latest trends on  Fashion Hub.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_url(text4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_8uKGlAN5EYt",
        "outputId": "45ca87ad-922f-4e39-c5af-0d0bb456d8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Connect with professionals on htttp=\" our networking platform.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic -: Punctuation are those symbols which we usually use for language formation such as full stop, exclamation, etc. below is list created which will help you to remove the punctuation marks. this list can be used in future lets say in projects where u dont consider # as punctuation u can simply remove that from the list.\n",
        "\n",
        "Why it is necessary to remove punctuation-: sentence is 'Hello', !, how, are, you,? so here puctuation like ! are unnecessarily added. so they are needed to be removed. sentence become long .\n",
        "\n",
        "projects like sentiment anlysis, text generation u dont need punctuation marks.\n",
        "\n",
        "2) if we apply tokenization on  'Hello', !, how, are, you,? the algorithm will consider Hello! and Hello as different  , same goes with you? and you. and model will get confuse further."
      ],
      "metadata": {
        "id": "7-QaA3iMxzAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "id": "xc-pVTh85flH",
        "outputId": "479fd811-4729-4669-ccc0-c7ed6dee1d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this gives u all the punctuation marks."
      ],
      "metadata": {
        "id": "WqfCKQyfAvyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exclude = string.punctuation"
      ],
      "metadata": {
        "id": "_ADcHo_pAft3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create a function that if any of the puncutation detected we will replace it with empty string."
      ],
      "metadata": {
        "id": "La_3UxVgA_jS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punc(text):\n",
        "    exclude = set(string.punctuation)  # Define exclude as a set of punctuation characters\n",
        "    for char in exclude:\n",
        "        text = text.replace(char, '')\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "hqP_yyl_A5ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world! How's everything going? Python's great, isn't it?\"\n"
      ],
      "metadata": {
        "id": "UI-IkSt0Bwwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(remove_punc(text))"
      ],
      "metadata": {
        "id": "bm-zL6gZB7E_",
        "outputId": "bebd0560-8676-48e8-e7cf-434b48715a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world Hows everything going Pythons great isnt it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "1Um10Rr_B-FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()                  # Start time\n",
        "print(remove_punc(text))              # Remove punctuation and print the result\n",
        "elapsed_time = time.time() - start    # Calculate elapsed time\n",
        "print(\"Time taken:\", elapsed_time)    # Print the elapsed time"
      ],
      "metadata": {
        "id": "GLzYAeEpCGWu",
        "outputId": "ea8438eb-6cc3-4045-ebcd-53a9403d9514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world Hows everything going Pythons great isnt it\n",
            "Time taken: 0.001493692398071289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for single sentence it takes so much of time or so many seconds so for atlkeast 50k sentence it would take more thn that."
      ],
      "metadata": {
        "id": "KvqqN4KSCxO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()                  # Start time\n",
        "print(remove_punc(text))              # Remove punctuation and print the result\n",
        "elapsed_time = time.time() - start    # Calculate elapsed time\n",
        "print(\"Time taken:\", elapsed_time*50000)    # Print the elapsed time"
      ],
      "metadata": {
        "id": "veiy23nJCXgW",
        "outputId": "4a740ca8-4e20-4e0d-f6e9-a7385af47557",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world Hows everything going Pythons great isnt it\n",
            "Time taken: 64.07499313354492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expression ('', '', string.punctuation) is used with str.maketrans to create a translation table that removes all punctuation from a string. Here’s a breakdown:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "str.maketrans('', '', string.punctuation)\n",
        "This translates to:\n",
        "\n",
        "The first two '' arguments specify that we don’t want to map any characters to other characters (if you wanted to replace characters, you’d put those here).\n",
        "The third argument, string.punctuation, is a string containing all common punctuation characters (!\"#$%&'()*+,-./:;<=>?@[\\]^_{|}~).\n",
        "So, str.maketrans('', '', string.punctuation) tells Python to map each punctuation character to None, effectively removing it when used with str.translate.\n",
        "\n",
        "\n",
        "The str.translate function with str.maketrans is generally more efficient for removing punctuation compared to other methods like looping through characters or using regular expressions. Here’s why it tends to be faster and more efficient:\n",
        "\n",
        "1. Optimized at the C Level\n",
        "str.translate and str.maketrans are implemented in C in the Python interpreter, making them very fast. These functions can operate on strings at the C level without the overhead of Python-level looping, making them faster than manually iterating over each character.\n",
        "2. Single Pass Over the String\n",
        "When using str.translate, the function makes only one pass over the string, applying the translation table directly. In contrast, other methods, like looping through characters or using str.replace in a loop, may involve multiple passes or checks, adding extra overhead.\n",
        "3. Memory Efficiency\n",
        "The translation table is a dictionary of character mappings, and each character is checked once against the table. Since the table is precomputed, str.translate only needs to look up each character once, rather than constructing or modifying multiple intermediate strings, which would require more memory and processing time."
      ],
      "metadata": {
        "id": "HSUX1XOHIk0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punct(text):\n",
        "    # Create a translation table that maps each punctuation to None\n",
        "    translator = str.maketrans('', '', exclude)\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "EQEvDp_9C8ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()                  # Start time\n",
        "print(remove_punct(text))              # Remove punctuation and print the result\n",
        "elapsedd_time = time.time() - start    # Calculate elapsed time\n",
        "print(\"Time taken:\", elapsedd_time)    # Print the elapsed time"
      ],
      "metadata": {
        "id": "oQ9lnfiCJp1T",
        "outputId": "25c85c18-f811-48c0-8807-193cd1b20d13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world Hows everything going Pythons great isnt it\n",
            "Time taken: 0.00026798248291015625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()                  # Start time\n",
        "print(remove_punct(text))              # Remove punctuation and print the result\n",
        "elapsedd_time = time.time() - start    # Calculate elapsed time\n",
        "print(\"Time taken:\", elapsedd_time*50000)"
      ],
      "metadata": {
        "id": "ZIcVIsc-Jwvf",
        "outputId": "ee9d6f80-ffd0-4439-be75-c3ee71a96fb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world Hows everything going Pythons great isnt it\n",
            "Time taken: 11.014938354492188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "how_fast = elapsed_time/elapsedd_time"
      ],
      "metadata": {
        "id": "waqxO-zYJ6bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "how_fast"
      ],
      "metadata": {
        "id": "nRrnYmsfKCEn",
        "outputId": "f0e5859a-7088-40e2-8812-50ab5a60f89d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.817099567099567"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "metadata": {
        "id": "QNANZCdXKDAO",
        "outputId": "351639c3-25d8-4438-ff77-c07dec57d5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "39335  canthony is correct that this little short is ...  positive\n",
              "22724  this definitely is not the intellectual film w...  positive\n",
              "31424  this classic has so many great one-liners and ...  positive\n",
              "42970  i have been getting into the hitchcock series ...  positive\n",
              "15596  other reviewers here seem to think this is an ...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b33ad611-3236-45de-a6e7-aede93e0aba4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39335</th>\n",
              "      <td>canthony is correct that this little short is ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22724</th>\n",
              "      <td>this definitely is not the intellectual film w...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31424</th>\n",
              "      <td>this classic has so many great one-liners and ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42970</th>\n",
              "      <td>i have been getting into the hitchcock series ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15596</th>\n",
              "      <td>other reviewers here seem to think this is an ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b33ad611-3236-45de-a6e7-aede93e0aba4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b33ad611-3236-45de-a6e7-aede93e0aba4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b33ad611-3236-45de-a6e7-aede93e0aba4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-295e8091-64ab-42e7-add9-d58b9ed81013\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-295e8091-64ab-42e7-add9-d58b9ed81013')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-295e8091-64ab-42e7-add9-d58b9ed81013 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"this definitely is not the intellectual film with profound mission, so i really don't think there is too much not to understand to in case you aren't czech.<br /><br />it's just a comedy. the humor is simple, pretty funny and sometimes, maybe, little morbid. some actors and characters are very similar to samot\\u00e1ri (2000) (jir\\u00ed mach\\u00e1cek, ivan trojan, vladim\\u00edr dlouh\\u00fd) so the authors are. but it doesn't matter, the genre is really different and these two films shouldn't be compared in this way. jedna ruka netlesk\\u00e1 won't try to give you a lesson, it will try to make you laugh and there is some chance it will succeed.<br /><br />not bad film, not the ingenious one, but i enjoyed it. some scenes are truly worth seeing.\",\n          \"other reviewers here seem to think this is an awful film. that's simply not true and a little unfair.<br /><br />the acting is of a good quality and the direction moves on with a decent fluidity. i don't think there's anything wrong with the tarantino-esquire way of interlocking stories together. perhaps its just a new tool for directors to try. i thought it made the film much more interesting. perhaps a few elements of the script need tightening, but that's about the only fault i can find. nestor cantillana gives a great performance as sylvio, also antonella rios is stunning and worth the price of admission alone.\",\n          \"this classic has so many great one-liners and unintentionally hilarious scenes that i don't even know where to start. if you want advice on dating, its here. just totally ignore the person you want, and then spout out classic lines like \\\"chicken's good...i like chicken\\\", and before you know it you will be having a one-nighter in a basement (it's a nice basement) with a woman who is 35 years younger than you. bronson does it all in this film. he buys a car for no good reason just so he can murder two gang members...paying with \\\"cash\\\"......chunnng.... he buys an ice cream, simply because \\\"this is america, isn't it\\\", and ends up wasting someone named \\\"the giggler - he laughs when he runs\\\" just because he stole his camera. by the way, this \\\"giggler\\\" is so fast that bronson's regular pistol can't even catch up to him, he needs to order a special one just to get this elusive creep. he gets cleaned up just so he can eat a really smelly meal (stuffed cabbage) in a rat trap with a couple of old people who like to wear heavy clothing in 90 degree weather. he goes into the dentistry business. he always seems to find a crow bar when he needs one (and its the same one!). and last, but not least, he always seems to have a rocket launcher at his disposal just in case he needs to blow away richie cunningham's older brother chuck who is now strung out and in dire need of a makeover. anyway, this will all make sense once you have seen this classic...all i can say is enjoy! \\\"i owed you that one dude\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'][3]"
      ],
      "metadata": {
        "id": "K6ne8thjMHQn",
        "outputId": "74caa224-f37e-4080-afb1-be81780899e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "all punctuations have been removed."
      ],
      "metadata": {
        "id": "gTHIyRsiOZCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_without_punct = data['review'].apply(remove_punct)"
      ],
      "metadata": {
        "id": "6Mz23VwbNIl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_without_punct[3]"
      ],
      "metadata": {
        "id": "Dx_G8W7xN6pf",
        "outputId": "28ee8008-e0bd-45c7-c9a9-1fb66216f6dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'basically theres a family where a little boy jake thinks theres a zombie in his closet  his parents are fighting all the timebr br this movie is slower than a soap opera and suddenly jake decides to become rambo and kill the zombiebr br ok first of all when youre going to make a film you must decide if its a thriller or a drama as a drama the movie is watchable parents are divorcing  arguing like in real life and then we have jake with his closet which totally ruins all the film i expected to see a boogeyman similar movie and instead i watched a drama with some meaningless thriller spotsbr br 3 out of 10 just for the well playing parents  descent dialogs as for the shots with jake just ignore them'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOPIC -: CHAT word treatment\n",
        "rofl, lamao, fyi, asap, gn, etc.. --> so we need to bring such words back to its normal form. where suppose its chatbot or whatsapp analyzer. etc. So how we will replace gn-> goodnight or asap-> as soon as possible and so on.."
      ],
      "metadata": {
        "id": "O3xQqFYMPWYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sms_translator github repo got the data from there . where i have 60 words which are abbrevations and we will copnvert them to normal form."
      ],
      "metadata": {
        "id": "2EDwOJ79S2WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_words = {\n",
        "    \"AFAIK\": \"As Far As I Know\",\n",
        "    \"AFK\": \"Away From Keyboard\",\n",
        "    \"ASAP\": \"As Soon As Possible\",\n",
        "    \"ATK\": \"At The Keyboard\",\n",
        "    \"ATM\": \"At The Moment\",\n",
        "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
        "    \"BAK\": \"Back At Keyboard\",\n",
        "    \"BBL\": \"Be Back Later\",\n",
        "    \"BBS\": \"Be Back Soon\",\n",
        "    \"BFN\": \"Bye For Now\",\n",
        "    \"B4N\": \"Bye For Now\",\n",
        "    \"BRB\": \"Be Right Back\",\n",
        "    \"BRT\": \"Be Right There\",\n",
        "    \"BTW\": \"By The Way\",\n",
        "    \"B4\": \"Before\",\n",
        "    \"CU\": \"See You\",\n",
        "    \"CUL8R\": \"See You Later\",\n",
        "    \"CYA\": \"See You\",\n",
        "    \"FAQ\": \"Frequently Asked Questions\",\n",
        "    \"FC\": \"Fingers Crossed\",\n",
        "    \"FWIW\": \"For What It's Worth\",\n",
        "    \"FYI\": \"For Your Information\",\n",
        "    \"GAL\": \"Get A Life\",\n",
        "    \"GG\": \"Good Game\",\n",
        "    \"GN\": \"Good Night\",\n",
        "    \"GMTA\": \"Great Minds Think Alike\",\n",
        "    \"GR8\": \"Great!\",\n",
        "    \"G9\": \"Genius\",\n",
        "    \"IC\": \"I See\",\n",
        "    \"ICQ\": \"I Seek you (also a chat program)\",\n",
        "    \"ILU\": \"I Love You\",\n",
        "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
        "    \"IMO\": \"In My Opinion\",\n",
        "    \"IOW\": \"In Other Words\",\n",
        "    \"IRL\": \"In Real Life\",\n",
        "    \"KISS\": \"Keep It Simple, Stupid\",\n",
        "    \"LDR\": \"Long Distance Relationship\",\n",
        "    \"LMAO\": \"Laugh My A.. Off\",\n",
        "    \"LOL\": \"Laughing Out Loud\",\n",
        "    \"LTNS\": \"Long Time No See\",\n",
        "    \"L8R\": \"Later\",\n",
        "    \"MTE\": \"My Thoughts Exactly\",\n",
        "    \"M8\": \"Mate\",\n",
        "    \"NRN\": \"No Reply Necessary\",\n",
        "    \"OIC\": \"Oh I See\",\n",
        "    \"PITA\": \"Pain In The A..\",\n",
        "    \"PRT\": \"Party\",\n",
        "    \"PRW\": \"Parents Are Watching\",\n",
        "    \"QPSA?\": \"Que Pasa?\",\n",
        "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
        "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
        "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
        "    \"SK8\": \"Skate\",\n",
        "    \"STATS\": \"Your sex and age\",\n",
        "    \"ASL\": \"Age, Sex, Location\",\n",
        "    \"THX\": \"Thank You\",\n",
        "    \"TTFN\": \"Ta-Ta For Now!\",\n",
        "    \"TTYL\": \"Talk To You Later\",\n",
        "    \"U\": \"You\",\n",
        "    \"U2\": \"You Too\",\n",
        "    \"U4E\": \"Yours For Ever\",\n",
        "    \"WB\": \"Welcome Back\",\n",
        "    \"WTF\": \"What The F...\",\n",
        "    \"WTG\": \"Way To Go!\",\n",
        "    \"WUF\": \"Where Are You From?\",\n",
        "    \"W8\": \"Wait...\",\n",
        "    \"7K\": \"Sick:-D Laugher\",\n",
        "    \"TFW\": \"That feeling when\",\n",
        "    \"MFW\": \"My face when\",\n",
        "    \"MRW\": \"My reaction when\",\n",
        "    \"IFYP\": \"I feel your pain\",\n",
        "    \"LOL\": \"Laughing out loud\",\n",
        "    \"TNTL\": \"Trying not to laugh\",\n",
        "    \"JK\": \"Just kidding\",\n",
        "    \"IDC\": \"I don’t care\",\n",
        "    \"ILY\": \"I love you\",\n",
        "    \"IMU\": \"I miss you\",\n",
        "    \"ADIH\": \"Another day in hell\",\n",
        "    \"ZZZ\": \"Sleeping, bored, tired\",\n",
        "    \"WYWH\": \"Wish you were here\",\n",
        "    \"TIME\": \"Tears in my eyes\",\n",
        "    \"BAE\": \"Before anyone else\",\n",
        "    \"FIMH\": \"Forever in my heart\",\n",
        "    \"BSAAW\": \"Big smile and a wink\",\n",
        "    \"BWL\": \"Bursting with laughter\",\n",
        "    \"BFF\": \"Best friends forever\",\n",
        "    \"CSL\": \"Can’t stop laughing\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "-lmZVwi-OBPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_words"
      ],
      "metadata": {
        "id": "48qow_YgTWd0",
        "outputId": "9fcb92c6-e329-4115-be19-3e6ae1e05f40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AFAIK': 'As Far As I Know',\n",
              " 'AFK': 'Away From Keyboard',\n",
              " 'ASAP': 'As Soon As Possible',\n",
              " 'ATK': 'At The Keyboard',\n",
              " 'ATM': 'At The Moment',\n",
              " 'A3': 'Anytime, Anywhere, Anyplace',\n",
              " 'BAK': 'Back At Keyboard',\n",
              " 'BBL': 'Be Back Later',\n",
              " 'BBS': 'Be Back Soon',\n",
              " 'BFN': 'Bye For Now',\n",
              " 'B4N': 'Bye For Now',\n",
              " 'BRB': 'Be Right Back',\n",
              " 'BRT': 'Be Right There',\n",
              " 'BTW': 'By The Way',\n",
              " 'B4': 'Before',\n",
              " 'CU': 'See You',\n",
              " 'CUL8R': 'See You Later',\n",
              " 'CYA': 'See You',\n",
              " 'FAQ': 'Frequently Asked Questions',\n",
              " 'FC': 'Fingers Crossed',\n",
              " 'FWIW': \"For What It's Worth\",\n",
              " 'FYI': 'For Your Information',\n",
              " 'GAL': 'Get A Life',\n",
              " 'GG': 'Good Game',\n",
              " 'GN': 'Good Night',\n",
              " 'GMTA': 'Great Minds Think Alike',\n",
              " 'GR8': 'Great!',\n",
              " 'G9': 'Genius',\n",
              " 'IC': 'I See',\n",
              " 'ICQ': 'I Seek you (also a chat program)',\n",
              " 'ILU': 'I Love You',\n",
              " 'IMHO': 'In My Honest/Humble Opinion',\n",
              " 'IMO': 'In My Opinion',\n",
              " 'IOW': 'In Other Words',\n",
              " 'IRL': 'In Real Life',\n",
              " 'KISS': 'Keep It Simple, Stupid',\n",
              " 'LDR': 'Long Distance Relationship',\n",
              " 'LMAO': 'Laugh My A.. Off',\n",
              " 'LOL': 'Laughing out loud',\n",
              " 'LTNS': 'Long Time No See',\n",
              " 'L8R': 'Later',\n",
              " 'MTE': 'My Thoughts Exactly',\n",
              " 'M8': 'Mate',\n",
              " 'NRN': 'No Reply Necessary',\n",
              " 'OIC': 'Oh I See',\n",
              " 'PITA': 'Pain In The A..',\n",
              " 'PRT': 'Party',\n",
              " 'PRW': 'Parents Are Watching',\n",
              " 'QPSA?': 'Que Pasa?',\n",
              " 'ROFL': 'Rolling On The Floor Laughing',\n",
              " 'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
              " 'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
              " 'SK8': 'Skate',\n",
              " 'STATS': 'Your sex and age',\n",
              " 'ASL': 'Age, Sex, Location',\n",
              " 'THX': 'Thank You',\n",
              " 'TTFN': 'Ta-Ta For Now!',\n",
              " 'TTYL': 'Talk To You Later',\n",
              " 'U': 'You',\n",
              " 'U2': 'You Too',\n",
              " 'U4E': 'Yours For Ever',\n",
              " 'WB': 'Welcome Back',\n",
              " 'WTF': 'What The F...',\n",
              " 'WTG': 'Way To Go!',\n",
              " 'WUF': 'Where Are You From?',\n",
              " 'W8': 'Wait...',\n",
              " '7K': 'Sick:-D Laugher',\n",
              " 'TFW': 'That feeling when',\n",
              " 'MFW': 'My face when',\n",
              " 'MRW': 'My reaction when',\n",
              " 'IFYP': 'I feel your pain',\n",
              " 'TNTL': 'Trying not to laugh',\n",
              " 'JK': 'Just kidding',\n",
              " 'IDC': 'I don’t care',\n",
              " 'ILY': 'I love you',\n",
              " 'IMU': 'I miss you',\n",
              " 'ADIH': 'Another day in hell',\n",
              " 'ZZZ': 'Sleeping, bored, tired',\n",
              " 'WYWH': 'Wish you were here',\n",
              " 'TIME': 'Tears in my eyes',\n",
              " 'BAE': 'Before anyone else',\n",
              " 'FIMH': 'Forever in my heart',\n",
              " 'BSAAW': 'Big smile and a wink',\n",
              " 'BWL': 'Bursting with laughter',\n",
              " 'BFF': 'Best friends forever',\n",
              " 'CSL': 'Can’t stop laughing'}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_conversion(text):\n",
        "    # Create an empty list to store the modified words\n",
        "    new_text = []\n",
        "\n",
        "    # Split the input text into words using whitespace as the delimiter\n",
        "    for word in text.split():\n",
        "        # Check if the uppercase version of the word exists in the 'chat_words' dictionary\n",
        "        if word.upper() in chat_words:\n",
        "            # If the word is a recognized chat abbreviation, append its full form to the list\n",
        "            new_text.append(chat_words[word.upper()])\n",
        "        else:\n",
        "            # If the word is not in the dictionary, append it as it is\n",
        "            new_text.append(word)\n",
        "\n",
        "    # Join the words in the new_text list into a single string and return it\n",
        "    return \" \".join(new_text)\n"
      ],
      "metadata": {
        "id": "N3ZwLAaBTXRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_conversion('GN see you tommorow')"
      ],
      "metadata": {
        "id": "yO1VCLCWUsTI",
        "outputId": "c3dbdc75-c74c-47e1-eb07-e6809a2ff5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Good Night see you tommorow'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_conversion('lmao nice joke')"
      ],
      "metadata": {
        "id": "lUd321uaVI7N",
        "outputId": "90c433da-ffd4-497f-f324-3bea8452dd2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Laugh My A.. Off nice joke'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_conversion('share me the money asap')"
      ],
      "metadata": {
        "id": "oq7jXbL4VNdX",
        "outputId": "4df1e028-f524-445c-a146-f3cbceca4e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'share me the money As Soon As Possible'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_conversion('fyi india is best country (not really)')"
      ],
      "metadata": {
        "id": "VeUyelKbVT3I",
        "outputId": "2c79380d-8eeb-450e-9d63-4c8b7c75c384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For Your Information india is best country (not really)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOPIC -: SPELLING CORRECTION\n",
        "\n",
        "Please read the note book, and also like the notebook. so when you tokenize the note book is 1 word but when tokenize it will become 2 words note and book. so this will create unnecessary complexities."
      ],
      "metadata": {
        "id": "F1WDm3pCV9Ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#try with TextBlob\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "LwWuhGfkVgv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_text = \"I lvoe to playy the guitarr and sing along to my favourit soongs.\""
      ],
      "metadata": {
        "id": "alMo-LgvX7Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textblb = TextBlob(incorrect_text)"
      ],
      "metadata": {
        "id": "34FXsfbqYQDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textblb.correct()"
      ],
      "metadata": {
        "id": "Hk-zVDU9YP8w",
        "outputId": "e524f57a-4132-43e4-8361-f366c4a84932",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"I love to play the guitar and sing along to my favourite songs.\")"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textblb.correct().string"
      ],
      "metadata": {
        "id": "j2gC7zJ-YeTN",
        "outputId": "0d53a3cf-4aa5-4831-939a-57a8312825b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I love to play the guitar and sing along to my favourite songs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOPIC - REMOVE STOPWORDS\n",
        "\n",
        "SOMETHING THAT CONTRIBUTES IN SENETENCE FORMATION BUT HAS NO MEANING SUCH AS A , THE , of, are, why so such words are used for formation of sentence but not in meaning of the sentence. nltk already has stopwords so u mostly use this library to remove them. Their are some tasks where you dont do stopwords removal for tasks like POS Tagging."
      ],
      "metadata": {
        "id": "5ufOnfF-Hv9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "M1Q8cx-RJ2yZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaybNXNbJ41x",
        "outputId": "a288ed6a-cfd0-4c1d-c2b9-58fc3351878c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "3K_La4NXYoVd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwDTgHaGJhIl",
        "outputId": "a94406f7-2e99-49de-cfe5-bf94c4fcfeb7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('spanish')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJjuqydeJhFk",
        "outputId": "b3ca7bd6-a751-4889-e4c4-ba995bbda18e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de',\n",
              " 'la',\n",
              " 'que',\n",
              " 'el',\n",
              " 'en',\n",
              " 'y',\n",
              " 'a',\n",
              " 'los',\n",
              " 'del',\n",
              " 'se',\n",
              " 'las',\n",
              " 'por',\n",
              " 'un',\n",
              " 'para',\n",
              " 'con',\n",
              " 'no',\n",
              " 'una',\n",
              " 'su',\n",
              " 'al',\n",
              " 'lo',\n",
              " 'como',\n",
              " 'más',\n",
              " 'pero',\n",
              " 'sus',\n",
              " 'le',\n",
              " 'ya',\n",
              " 'o',\n",
              " 'este',\n",
              " 'sí',\n",
              " 'porque',\n",
              " 'esta',\n",
              " 'entre',\n",
              " 'cuando',\n",
              " 'muy',\n",
              " 'sin',\n",
              " 'sobre',\n",
              " 'también',\n",
              " 'me',\n",
              " 'hasta',\n",
              " 'hay',\n",
              " 'donde',\n",
              " 'quien',\n",
              " 'desde',\n",
              " 'todo',\n",
              " 'nos',\n",
              " 'durante',\n",
              " 'todos',\n",
              " 'uno',\n",
              " 'les',\n",
              " 'ni',\n",
              " 'contra',\n",
              " 'otros',\n",
              " 'ese',\n",
              " 'eso',\n",
              " 'ante',\n",
              " 'ellos',\n",
              " 'e',\n",
              " 'esto',\n",
              " 'mí',\n",
              " 'antes',\n",
              " 'algunos',\n",
              " 'qué',\n",
              " 'unos',\n",
              " 'yo',\n",
              " 'otro',\n",
              " 'otras',\n",
              " 'otra',\n",
              " 'él',\n",
              " 'tanto',\n",
              " 'esa',\n",
              " 'estos',\n",
              " 'mucho',\n",
              " 'quienes',\n",
              " 'nada',\n",
              " 'muchos',\n",
              " 'cual',\n",
              " 'poco',\n",
              " 'ella',\n",
              " 'estar',\n",
              " 'estas',\n",
              " 'algunas',\n",
              " 'algo',\n",
              " 'nosotros',\n",
              " 'mi',\n",
              " 'mis',\n",
              " 'tú',\n",
              " 'te',\n",
              " 'ti',\n",
              " 'tu',\n",
              " 'tus',\n",
              " 'ellas',\n",
              " 'nosotras',\n",
              " 'vosotros',\n",
              " 'vosotras',\n",
              " 'os',\n",
              " 'mío',\n",
              " 'mía',\n",
              " 'míos',\n",
              " 'mías',\n",
              " 'tuyo',\n",
              " 'tuya',\n",
              " 'tuyos',\n",
              " 'tuyas',\n",
              " 'suyo',\n",
              " 'suya',\n",
              " 'suyos',\n",
              " 'suyas',\n",
              " 'nuestro',\n",
              " 'nuestra',\n",
              " 'nuestros',\n",
              " 'nuestras',\n",
              " 'vuestro',\n",
              " 'vuestra',\n",
              " 'vuestros',\n",
              " 'vuestras',\n",
              " 'esos',\n",
              " 'esas',\n",
              " 'estoy',\n",
              " 'estás',\n",
              " 'está',\n",
              " 'estamos',\n",
              " 'estáis',\n",
              " 'están',\n",
              " 'esté',\n",
              " 'estés',\n",
              " 'estemos',\n",
              " 'estéis',\n",
              " 'estén',\n",
              " 'estaré',\n",
              " 'estarás',\n",
              " 'estará',\n",
              " 'estaremos',\n",
              " 'estaréis',\n",
              " 'estarán',\n",
              " 'estaría',\n",
              " 'estarías',\n",
              " 'estaríamos',\n",
              " 'estaríais',\n",
              " 'estarían',\n",
              " 'estaba',\n",
              " 'estabas',\n",
              " 'estábamos',\n",
              " 'estabais',\n",
              " 'estaban',\n",
              " 'estuve',\n",
              " 'estuviste',\n",
              " 'estuvo',\n",
              " 'estuvimos',\n",
              " 'estuvisteis',\n",
              " 'estuvieron',\n",
              " 'estuviera',\n",
              " 'estuvieras',\n",
              " 'estuviéramos',\n",
              " 'estuvierais',\n",
              " 'estuvieran',\n",
              " 'estuviese',\n",
              " 'estuvieses',\n",
              " 'estuviésemos',\n",
              " 'estuvieseis',\n",
              " 'estuviesen',\n",
              " 'estando',\n",
              " 'estado',\n",
              " 'estada',\n",
              " 'estados',\n",
              " 'estadas',\n",
              " 'estad',\n",
              " 'he',\n",
              " 'has',\n",
              " 'ha',\n",
              " 'hemos',\n",
              " 'habéis',\n",
              " 'han',\n",
              " 'haya',\n",
              " 'hayas',\n",
              " 'hayamos',\n",
              " 'hayáis',\n",
              " 'hayan',\n",
              " 'habré',\n",
              " 'habrás',\n",
              " 'habrá',\n",
              " 'habremos',\n",
              " 'habréis',\n",
              " 'habrán',\n",
              " 'habría',\n",
              " 'habrías',\n",
              " 'habríamos',\n",
              " 'habríais',\n",
              " 'habrían',\n",
              " 'había',\n",
              " 'habías',\n",
              " 'habíamos',\n",
              " 'habíais',\n",
              " 'habían',\n",
              " 'hube',\n",
              " 'hubiste',\n",
              " 'hubo',\n",
              " 'hubimos',\n",
              " 'hubisteis',\n",
              " 'hubieron',\n",
              " 'hubiera',\n",
              " 'hubieras',\n",
              " 'hubiéramos',\n",
              " 'hubierais',\n",
              " 'hubieran',\n",
              " 'hubiese',\n",
              " 'hubieses',\n",
              " 'hubiésemos',\n",
              " 'hubieseis',\n",
              " 'hubiesen',\n",
              " 'habiendo',\n",
              " 'habido',\n",
              " 'habida',\n",
              " 'habidos',\n",
              " 'habidas',\n",
              " 'soy',\n",
              " 'eres',\n",
              " 'es',\n",
              " 'somos',\n",
              " 'sois',\n",
              " 'son',\n",
              " 'sea',\n",
              " 'seas',\n",
              " 'seamos',\n",
              " 'seáis',\n",
              " 'sean',\n",
              " 'seré',\n",
              " 'serás',\n",
              " 'será',\n",
              " 'seremos',\n",
              " 'seréis',\n",
              " 'serán',\n",
              " 'sería',\n",
              " 'serías',\n",
              " 'seríamos',\n",
              " 'seríais',\n",
              " 'serían',\n",
              " 'era',\n",
              " 'eras',\n",
              " 'éramos',\n",
              " 'erais',\n",
              " 'eran',\n",
              " 'fui',\n",
              " 'fuiste',\n",
              " 'fue',\n",
              " 'fuimos',\n",
              " 'fuisteis',\n",
              " 'fueron',\n",
              " 'fuera',\n",
              " 'fueras',\n",
              " 'fuéramos',\n",
              " 'fuerais',\n",
              " 'fueran',\n",
              " 'fuese',\n",
              " 'fueses',\n",
              " 'fuésemos',\n",
              " 'fueseis',\n",
              " 'fuesen',\n",
              " 'sintiendo',\n",
              " 'sentido',\n",
              " 'sentida',\n",
              " 'sentidos',\n",
              " 'sentidas',\n",
              " 'siente',\n",
              " 'sentid',\n",
              " 'tengo',\n",
              " 'tienes',\n",
              " 'tiene',\n",
              " 'tenemos',\n",
              " 'tenéis',\n",
              " 'tienen',\n",
              " 'tenga',\n",
              " 'tengas',\n",
              " 'tengamos',\n",
              " 'tengáis',\n",
              " 'tengan',\n",
              " 'tendré',\n",
              " 'tendrás',\n",
              " 'tendrá',\n",
              " 'tendremos',\n",
              " 'tendréis',\n",
              " 'tendrán',\n",
              " 'tendría',\n",
              " 'tendrías',\n",
              " 'tendríamos',\n",
              " 'tendríais',\n",
              " 'tendrían',\n",
              " 'tenía',\n",
              " 'tenías',\n",
              " 'teníamos',\n",
              " 'teníais',\n",
              " 'tenían',\n",
              " 'tuve',\n",
              " 'tuviste',\n",
              " 'tuvo',\n",
              " 'tuvimos',\n",
              " 'tuvisteis',\n",
              " 'tuvieron',\n",
              " 'tuviera',\n",
              " 'tuvieras',\n",
              " 'tuviéramos',\n",
              " 'tuvierais',\n",
              " 'tuvieran',\n",
              " 'tuviese',\n",
              " 'tuvieses',\n",
              " 'tuviésemos',\n",
              " 'tuvieseis',\n",
              " 'tuviesen',\n",
              " 'teniendo',\n",
              " 'tenido',\n",
              " 'tenida',\n",
              " 'tenidos',\n",
              " 'tenidas',\n",
              " 'tened']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "  new_text = []\n",
        "  for words in text.split():\n",
        "    if words in stopwords.words('english'):\n",
        "      new_text.append('')\n",
        "    else:\n",
        "      new_text.append(words)\n",
        "  return ' '.join(new_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "kiGn7Sp2JhCk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Although it was not the best of times, she could still see that through all of it, he had always been there by her side, with neither of them willing to let go or walk away.\""
      ],
      "metadata": {
        "id": "FkBf38UNQdv7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_stopwords(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-jQBlwAmJg_2",
        "outputId": "7d62264d-71e8-4770-8c3d-f67a98fd87d0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Although     best  times,  could still see     it,   always     side,  neither   willing  let go  walk away.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "  new_text = []\n",
        "  for words in text.split():\n",
        "    if words in stopwords.words('english'):\n",
        "      new_text.append('')\n",
        "    else:\n",
        "      new_text.append(words)\n",
        "  x = new_text[:]\n",
        "  new_text.clear()\n",
        "  return ' '.join(x)"
      ],
      "metadata": {
        "id": "N1os0PGgJg8z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"When the sun sets behind the mountains, the sky transforms into a canvas of colors that fade slowly into the night.\""
      ],
      "metadata": {
        "id": "tpSF3tsDJg5q"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_stopwords(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hD6EoDUxUZTj",
        "outputId": "f00b0e9b-0244-4d92-8903-a6eec4553f0e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'When  sun sets behind  mountains,  sky transforms   canvas  colors  fade slowly   night.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can apply entire fucntion on your reviews data. you can directlky use data['reviews'].apply(function_name)."
      ],
      "metadata": {
        "id": "LqJ4Ls6JZkx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEXT TOPIC - REMOVE EMOJIS\n",
        "To express our emotions we use emojis in our chat. so while analysis our machine learning algorithms might not understand those emojis. either we can remove them or replace with its meaning. suppose a happy emoji can be replaced with its meaning word 'happy'."
      ],
      "metadata": {
        "id": "BLssjjHFapbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so two options are 1) remove and 2) is replace"
      ],
      "metadata": {
        "id": "7SocBdMIdoTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "e94clMHseerY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emojis(text):\n",
        "    # This regex pattern covers a broader range of emojis\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\\U0001F600-\\U0001F64F\"  # Emoticons\n",
        "        \"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
        "        \"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
        "        \"\\U0001F700-\\U0001F77F\"  # Alchemical symbols\n",
        "        \"\\U0001F780-\\U0001F7FF\"  # Geometric shapes extended\n",
        "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental symbols and pictographs\n",
        "        \"\\U0001F900-\\U0001F9FF\"  # Emoticons & other symbols\n",
        "        \"\\U0001FA00-\\U0001FA6F\"  # Symbol & pictographs (including modern emojis)\n",
        "        \"\\U0001F000-\\U0001F02F\"  # Mahjong tiles\n",
        "        \"\\U00002000-\\U00002B50\"  # Various symbols, stars, etc.\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n"
      ],
      "metadata": {
        "id": "c0nOBSldUbgt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_emojis(\"Hello! 🌟 Let's remove emojis 🤖 from this text! 🚀\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sc57Nzk1ePtp",
        "outputId": "4f48a53e-8da5-43d2-9440-a71c030f197e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello!  Let's remove emojis  from this text! \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if i want to replace emoji with its meaning do the following-:"
      ],
      "metadata": {
        "id": "cD7-AjnEe_Be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TViD50Jve7Nw",
        "outputId": "9cff56b5-f29a-4fc3-893a-07cbc956c088"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji"
      ],
      "metadata": {
        "id": "A4dwWejAfJO1"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(emoji.demojize(\"Hello! 🌟 Let's remove emojis 🤖 from this text! 🚀\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81Vt8H0NfQ9t",
        "outputId": "f10669c7-7250-493e-8f38-08e1f40369b4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! :glowing_star: Let's remove emojis :robot: from this text! :rocket:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(emoji.demojize(\"Python is 🔥 and it's changing the world!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMqoRjoIfrpg",
        "outputId": "818a1969-d881-4b09-dfb6-361f2102cbf2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python is :fire: and it's changing the world!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOPIC-: TOKENIZATION\n",
        "\n",
        "\n",
        "### **Tokenization Explained:**\n",
        "Tokenization is the process of splitting a piece of text into smaller, meaningful units, known as *tokens*. Tokens can be words, subwords, characters, or symbols. For example, in word-level tokenization, the sentence:\n",
        "\n",
        "**\"I love programming!\"**\n",
        "\n",
        "would be split into tokens:\n",
        "\n",
        "```\n",
        "['I', 'love', 'programming', '!']\n",
        "```\n",
        "\n",
        "In subword tokenization, it could break down even further, especially useful for handling out-of-vocabulary words.\n",
        "\n",
        "**Why Do We Need Tokenization?**\n",
        "\n",
        "1. **Text Representation:**\n",
        "   Tokenization helps break down a complex sentence into simpler pieces that can be processed by a machine learning model. Text data is typically unstructured, so tokenization converts it into a structured format that can be fed into algorithms.\n",
        "\n",
        "2. **Handling Language Variability:**\n",
        "   Different languages have different structures, word forms, and expressions. Tokenization helps deal with these variations by breaking down text into standard units that can be easily analyzed or modeled.\n",
        "\n",
        "3. **Improving Model Efficiency:**\n",
        "   Models can only handle tokens, not raw text. Tokenization makes it easier for models (like neural networks) to learn patterns in data.\n",
        "\n",
        "### **Advantages of Tokenization:**\n",
        "\n",
        "1. **Simplicity in Text Representation:**\n",
        "   Tokenization simplifies a sentence by breaking it down into basic units, making it easier to analyze. This helps machine learning models focus on the relationships between tokens, such as word dependencies or sentiment analysis.\n",
        "\n",
        "2. **Enabling Further Processing:**\n",
        "   After tokenization, other important tasks like part-of-speech tagging, named entity recognition, and text classification can be performed.\n",
        "\n",
        "3. **Dealing with Variable Lengths:**\n",
        "   Tokenization can standardize variable-length text data. This is especially useful for text input to deep learning models, which often require fixed-length inputs. For example, tokenizing into subword units (using approaches like BPE or WordPiece) can help address issues like unknown words and out-of-vocabulary tokens.\n",
        "\n",
        "4. **Improved Handling of Multilingual Text:**\n",
        "   Tokenization makes it easier to handle texts in multiple languages by separating the text into smaller, manageable units. It also helps in translating one language to another.\n",
        "\n",
        "---\n",
        "\n",
        "### **Challenges and Issues in Tokenization:**\n",
        "\n",
        "Despite its importance, tokenization can face several challenges due to the complexities of natural language. Some of the main issues include:\n",
        "\n",
        "1. **Prefix (e.g., \"un\" in \"untidy\"):**\n",
        "   Tokenizing words with prefixes can lead to ambiguity. For instance, the prefix *\"un\"* in *\"untidy\"* makes the meaning of the token dependent on the context. Tokenization may split *\"untidy\"* into *[\"un\", \"tidy\"]* which could affect understanding in certain NLP tasks.\n",
        "\n",
        "   **Example:**\n",
        "   - \"untidy\" → Tokenized as [\"un\", \"tidy\"]\n",
        "   - This can create confusion because \"un\" is a common prefix, but it may not always make sense as a standalone token.\n",
        "\n",
        "2. **Suffix (e.g., \"ing\" in \"running\"):**\n",
        "   Suffixes can make tokenization more challenging. The suffix *\"ing\"* in *\"running\"* might need to be removed or handled specially for accurate tokenization, especially when dealing with morphology in NLP.\n",
        "\n",
        "   **Example:**\n",
        "   - \"running\" → Tokenized as [\"run\", \"ing\"]\n",
        "   - While this can be helpful in certain tasks like stemming or lemmatization, it's not always desired because \"running\" and \"run\" may have different meanings or functions in a sentence.\n",
        "\n",
        "3. **Infix (e.g., apostrophes in contractions like \"don't\"):**\n",
        "   Infixes are parts of words that occur in the middle. Contractions like *\"don't\"* or *\"I'm\"* often pose problems because tokenizers may split them into parts, leading to misunderstanding of the context or meaning.\n",
        "\n",
        "   **Example:**\n",
        "   - \"don't\" → Tokenized as [\"do\", \"'\", \"n't\"]\n",
        "   - This split may lose the meaning of the contraction. For example, \"don't\" should be treated as a single token because it means \"do not,\" not \"do\" and \"not\" separately.\n",
        "\n",
        "4. **Exceptions (e.g., punctuation, special characters):**\n",
        "   Punctuation marks, special symbols, or slang can complicate tokenization. For example, a tokenizer might misinterpret punctuation like periods or commas, which are often part of larger sentence structures.\n",
        "\n",
        "   **Example:**\n",
        "   - \"Hello! How are you?\" → Tokenized as [\"Hello\", \"!\", \"How\", \"are\", \"you\", \"?\"]\n",
        "   - Special cases, such as punctuation marks, should be treated properly. Some tokenizers might not recognize *\"!\"* and *\"?\"* as sentence boundaries, which could lead to incorrect processing in tasks like sentiment analysis or sentence segmentation.\n",
        "\n",
        "### **Summary of Challenges:**\n",
        "\n",
        "- **Prefix Issue:** Breaking words into a prefix and root may change the meaning.\n",
        "- **Suffix Issue:** Tokenizing suffixes (e.g., *-ing*) may affect the word's intended meaning.\n",
        "- **Infix Issue:** Handling contractions and possessive forms (e.g., *don't* or *John's*) can lead to loss of meaning.\n",
        "- **Exceptions:** Special characters or punctuation might confuse the tokenizer, leading to inaccurate tokenization.\n",
        "\n",
        "By addressing these challenges, tokenization can be optimized to handle various linguistic complexities, making it a key preprocessing step for NLP tasks."
      ],
      "metadata": {
        "id": "KnubsHramgkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tecniques to apply tokenization"
      ],
      "metadata": {
        "id": "Uf7-bEg6moI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using a split function directly\n",
        "sent1 = \"Hello how are you, hope your in good health\"\n",
        "print(sent1.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeIBUyASf0Fd",
        "outputId": "b448be39-e0e8-46bc-9818-0ea282f547a1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'how', 'are', 'you,', 'hope', 'your', 'in', 'good', 'health']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent2 = \"Hello how are you? hope your in good health. Sorry i cannot visit you becuase I'm travelling.\"\n",
        "print(sent2.split('.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYR3QfCom5dv",
        "outputId": "2b592acb-a385-4b56-a1cf-5e342c24f2bf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello how are you? hope your in good health', \" Sorry i cannot visit you becuase I'm travelling\", '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "roblems with split() in Tokenization:\n",
        "Contractions (e.g., \"I'M\"):\n",
        "\n",
        "The word \"I'M\" is not split correctly. The apostrophe is part of the token, and it's treated as one unit. Ideally, a tokenizer should split it into \"I\" and \"M\" or treat it as a single entity (\"I'm\") depending on the context.\n",
        "Problem: Tokenizing contractions like \"I'm\", \"don't\", or \"they're\" often results in incorrect splits, as the tokenizer doesn't understand that the apostrophe is part of the contraction and shouldn't always be separated.\n",
        "Punctuation (e.g., \"delhi!\"):\n",
        "\n",
        "The word \"delhi!\" includes punctuation that is often significant for tasks like sentiment analysis or parsing, but it is treated as part of the token. In many NLP tasks, you would want to separate the punctuation (\"!\") from the word \"delhi\".\n",
        "Problem: Without proper handling, punctuation like \"!\", \".\", \",\", etc., are treated as part of the word, which can cause confusion in later steps such as sentence segmentation or sentiment classification.\n",
        "Lack of Context Understanding:\n",
        "\n",
        "The split() function is basic and doesn't take into account more complex language features such as morphology (e.g., handling prefixes and suffixes) or semantic structure.\n",
        "Problem: It doesn't understand context or the role of punctuation, so it doesn't know when two tokens should be joined or when punctuation should be treated as separate.\n",
        "How to Improve Tokenization:\n",
        "Handling Contractions:\n",
        "\n",
        "A more advanced tokenizer will recognize contractions like \"I'm\", \"don't\", and \"they're\", and treat them as either single tokens or separate tokens with correct context. For example, \"I'm\" should be tokenized as \"I\" and \"am\".\n",
        "Separation of Punctuation:\n",
        "\n",
        "You should separate punctuation marks like \"!\", \".\", and \",\" into their own tokens, treating them as meaningful elements in the sentence structure."
      ],
      "metadata": {
        "id": "uc4iyi1npNKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#problems with split functions\n",
        "sent3 = \"I'M going to delhi!\"\n",
        "print(sent3.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5FEKJGOn8hP",
        "outputId": "4c01b6c8-c42b-4884-d720-50b60e7c50bb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"I'M\", 'going', 'to', 'delhi!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)nd option is regular expression . but here punctutation will be removed but what if i need punctutation so there it might create a problem."
      ],
      "metadata": {
        "id": "l0r4DbBypVKg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Issues You Might Face with Regex:\n",
        "Over-Splitting or Under-Splitting:\n",
        "\n",
        "Problem: A simple regex might over-split some elements, such as contractions (\"I'm\" → [\"I\", \"'m\"]), or it could fail to recognize certain complex structures (e.g., abbreviations like \"U.S.\").\n",
        "Solution: You can customize the regex to handle these cases, but as text becomes more complex, regex-based tokenization can get harder to manage effectively.\n",
        "Edge Cases:\n",
        "\n",
        "Problem: Complex text structures or rare punctuation can lead to failures in correctly tokenizing.\n",
        "Solution: Regular expressions need to be tailored specifically to handle edge cases in your data.\n",
        "Punctuation Retention:\n",
        "\n",
        "Problem: Sometimes, you might want to retain punctuation but also keep it separate from words, especially when punctuation carries meaning (like question marks, exclamation points, or commas).\n",
        "Solution: Modify the regex to capture punctuation correctly without removing it. Using [^\\w\\s] ensures punctuation is captured separately, but certain punctuation types (like apostrophes in contractions) might still require additional handlin"
      ],
      "metadata": {
        "id": "IKFO3joXqavr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "sent3 = \"I'm going to delhi!\"\n",
        "tokens = re.findall(\"[\\w]+\",sent3)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNylN2ENo4WY",
        "outputId": "a8d5b16b-2232-476b-9ac8-3c68c4985af0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'm', 'going', 'to', 'delhi']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So if you dont want to face any of these problems you can use libraries ."
      ],
      "metadata": {
        "id": "D3LbCW8Mqihs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOPIC - NLTK\n",
        "\n",
        "\n",
        "When it comes to tokenization and other natural language processing (NLP) tasks, using dedicated libraries like NLTK, spaCy, or Hugging Face's Transformers is often the best approach. These libraries already come with sophisticated, pre-built algorithms that can handle various scenarios effectively. Let me elaborate on why using these libraries is the preferred choice:\n",
        "\n",
        "Why Use Libraries Like NLTK, spaCy, or Transformers?\n",
        "Pre-trained Models:\n",
        "\n",
        "Libraries like spaCy and Hugging Face's Transformers come with pre-trained models that have been fine-tuned on vast amounts of text. These models are able to handle complex tokenization tasks, including dealing with contractions, punctuation, special characters, and even edge cases like hashtags or emojis.\n",
        "Handling Contractions, Punctuation, and Edge Cases:\n",
        "\n",
        "NLTK and spaCy both have tokenizers that can intelligently split contractions (like \"I'm\" into [\"I\", \"'m\"]) and handle punctuation marks correctly (such as separating \"!\", \".\", and \",\" from words).\n",
        "In contrast, using simple split() or regex approaches might not correctly address all these cases.\n",
        "Efficiency and Robustness:\n",
        "\n",
        "Pre-built tokenizers in libraries like spaCy are highly efficient, optimized for performance, and handle large datasets effectively.\n",
        "They account for a variety of scenarios, including punctuation, special characters, multi-word expressions, and token normalization (e.g., handling upper and lowercase text).\n",
        "Language-Specific Tokenization:\n",
        "\n",
        "Libraries like spaCy and Hugging Face support multiple languages, and their tokenizers are tailored to the peculiarities of different languages. For instance, tokenization in Chinese or Arabic may require specific handling, which is built into these libraries.\n",
        "Built-in Features Beyond Tokenization:\n",
        "\n",
        "NLTK, spaCy, and Hugging Face don't just provide tokenization. They also offer lemmatization, stemming, POS tagging, dependency parsing, and named entity recognition (NER), which makes these libraries an excellent choice for comprehensive text processing."
      ],
      "metadata": {
        "id": "AevPecJMqokp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifXurlY-rNPh",
        "outputId": "f8c0b154-84a2-4b7b-adf1-1b28b7fd59fd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "laYQTibTrJWh"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PRheIdIspVj",
        "outputId": "0a8ee0db-f995-4de8-cd63-a3c8e2e235d3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n"
      ],
      "metadata": {
        "id": "OaS_FCF0qCWP"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent4 = \"I'm going to delhi!\"\n",
        "word_tokenize(sent4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtR7qwIOsX3V",
        "outputId": "4fabda93-0271-4809-f3b4-d9d3c2e2aff3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', \"'m\", 'going', 'to', 'delhi', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent5 = \"The quick brown fox jumps over the lazy dog near the old, abandoned house at the edge of the forest, where the wind whispers through the trees, and the moonlight flickers in the distance.\""
      ],
      "metadata": {
        "id": "lx4GnIhzsX0D"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(sent5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M50uJq_1rIS4",
        "outputId": "73963a3c-6d38-45f2-fb9d-987aed1d5dfa"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'quick',\n",
              " 'brown',\n",
              " 'fox',\n",
              " 'jumps',\n",
              " 'over',\n",
              " 'the',\n",
              " 'lazy',\n",
              " 'dog',\n",
              " 'near',\n",
              " 'the',\n",
              " 'old',\n",
              " ',',\n",
              " 'abandoned',\n",
              " 'house',\n",
              " 'at',\n",
              " 'the',\n",
              " 'edge',\n",
              " 'of',\n",
              " 'the',\n",
              " 'forest',\n",
              " ',',\n",
              " 'where',\n",
              " 'the',\n",
              " 'wind',\n",
              " 'whispers',\n",
              " 'through',\n",
              " 'the',\n",
              " 'trees',\n",
              " ',',\n",
              " 'and',\n",
              " 'the',\n",
              " 'moonlight',\n",
              " 'flickers',\n",
              " 'in',\n",
              " 'the',\n",
              " 'distance',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(sent5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VrktO5Ns8rY",
        "outputId": "b98bc156-ea7e-4b58-fb2b-ebb9a8720f9f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The quick brown fox jumps over the lazy dog near the old, abandoned house at the edge of the forest, where the wind whispers through the trees, and the moonlight flickers in the distance.']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent6 = \"\"\"The quick brown fox jumps over the lazy dog. Near the forest, the trees swayed in the wind.\n",
        "As the moonlight bathed the landscape, everything seemed still and quiet.\"\"\""
      ],
      "metadata": {
        "id": "9oILZviJtBhg"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(sent6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXfs8JeotPZp",
        "outputId": "6984689a-d79e-41d0-c43e-4a75b11f838a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The quick brown fox jumps over the lazy dog.',\n",
              " 'Near the forest, the trees swayed in the wind.',\n",
              " 'As the moonlight bathed the landscape, everything seemed still and quiet.']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk also fails when it comes to identify mails. it breakdown the mails aswell."
      ],
      "metadata": {
        "id": "hSWfxXcytcHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent7 = \"my mail is abc@gmail.com\"\n",
        "word_tokenize(sent7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpuNrFBetRcZ",
        "outputId": "df2f2a2c-a025-4117-b0e5-a4af4efb31a4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my', 'mail', 'is', 'abc', '@', 'gmail.com']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#spacy is personally best for tokenizaTION\n",
        "import spacy\n",
        "#load the dict of eng\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "zFicrmTktl_A"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert text into doc in spacy to apply tokenization\n",
        "doc1 = nlp(sent5)\n",
        "doc2 = nlp(sent6)\n",
        "doc3 = nlp(sent7)\n",
        "doc4 = nlp(sent4)"
      ],
      "metadata": {
        "id": "zsR8OF_xtyX5"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in doc3:\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bzqtIA3uPIp",
        "outputId": "000913da-0824-425d-b9f7-74f1bcf7da7d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my\n",
            "mail\n",
            "is\n",
            "abc@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc4:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw6t7D3wuYnB",
        "outputId": "e708f9a7-18eb-4028-9d48-ca3f9b043c8b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "'m\n",
            "going\n",
            "to\n",
            "delhi\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for new_token in doc2:\n",
        "  print(new_token)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kDLNGoNudTZ",
        "outputId": "a553d79d-e162-4083-d302-5d4d2a64a2ed"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The\n",
            "quick\n",
            "brown\n",
            "fox\n",
            "jumps\n",
            "over\n",
            "the\n",
            "lazy\n",
            "dog\n",
            ".\n",
            "Near\n",
            "the\n",
            "forest\n",
            ",\n",
            "the\n",
            "trees\n",
            "swayed\n",
            "in\n",
            "the\n",
            "wind\n",
            ".\n",
            "\n",
            "\n",
            "As\n",
            "the\n",
            "moonlight\n",
            "bathed\n",
            "the\n",
            "landscape\n",
            ",\n",
            "everything\n",
            "seemed\n",
            "still\n",
            "and\n",
            "quiet\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOPIC - STEMMING\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Stemming in Natural Language Processing (NLP)\n",
        "Stemming is the process of reducing a word to its base or root form. This is especially useful in NLP tasks as it helps to group words with similar meanings together and reduces complexity by standardizing different forms of words.\n",
        "\n",
        "Why Stemming is Useful\n",
        "Normalization: Stemming helps in normalizing words to their base form, enabling algorithms to process different forms of words as equivalent. For example, \"running\", \"runner\", and \"ran\" can all be reduced to \"run\".\n",
        "Reduces Data Size: In tasks like information retrieval, stemming helps reduce the data's dimensionality by mapping different forms of words to a single root.\n",
        "Search Optimization: By stemming query terms and indexed terms to their base forms, search engines can retrieve relevant results regardless of the word's inflection.\n",
        "Advantages of Stemming\n",
        "Efficiency: Simplifies large data processing by consolidating different word forms.\n",
        "Improved Matching: Groups related words, making it easier to match queries with relevant documents or phrases.\n",
        "Linguistic Consistency: Makes text processing tasks simpler by reducing variation.\n",
        "Common Problems Faced in Stemming\n",
        "Overstemming (Aggressive Reduction): When the stemmer reduces words beyond their intended base form. For example, \"university\" might incorrectly reduce to \"univers\".\n",
        "Understemming (Insufficient Reduction): When the stemmer fails to reduce related words to a common base. For instance, \"relational\" and \"relation\" might not stem to the same form.\n",
        "Ambiguity with Prefixes and Suffixes: Stemming may encounter issues where prefixes or suffixes alter the meaning, e.g., \"disappear\" and \"appear\".\n",
        "Examples of Stemming Issues\n",
        "Overstemming:\n",
        "\n",
        "Input: \"university\"\n",
        "Result: \"univers\" (This might lose meaning)\n",
        "Understemming:\n",
        "\n",
        "Input: \"relation\" and \"relational\"\n",
        "Result: \"relation\" and \"relational\" (They don't reduce to the same form)\n",
        "Prefix Issue:\n",
        "\n",
        "Input: \"disappear\" vs. \"appear\"\n",
        "Result: \"disappear\" → \"disappear\", \"appear\" → \"appear\" (Incorrectly treated as unrelated words)\n",
        "Suffix Issue:\n",
        "\n",
        "Input: \"happiness\" and \"happy\"\n",
        "Result: \"happi\" and \"happi\" (Desired)"
      ],
      "metadata": {
        "id": "lYlzVQmyu2DL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Absolutely! Your example perfectly illustrates why **stemming** is crucial in **Information Retrieval (IR) systems**.\n",
        "\n",
        "### Explanation:\n",
        "\n",
        "- **Problem Scenario**: Suppose a user searches for \"fishing\" but the system only retrieves documents containing \"fish\" and misses out on relevant content. This indicates a problem with how the system processes words. Without stemming, the system treats \"fish\" and \"fishing\" as unrelated terms, leading to a failure in retrieving relevant information for variations of a word.\n",
        "- **Solution Using Stemming**: By using a stemming algorithm, the IR system can map both \"fish\" and \"fishing\" to a common root (e.g., \"fish\"). This ensures that all related documents are retrieved, regardless of the word form used in the query.\n",
        "\n",
        "### How Stemming Helps:\n",
        "\n",
        "1. **Broadens Search Results**: It groups different forms of a word into a single term, allowing the system to retrieve documents containing any form of the word (e.g., \"fish\", \"fishing\", \"fisher\").\n",
        "2. **Increases Recall**: The system becomes more inclusive by matching variations of terms, which is essential for comprehensive information retrieval.\n",
        "3. **Consistency Across Queries**: Ensures that similar words are treated equally, making the search behavior consistent and user-friendly.\n",
        "\n",
        "---\n",
        "\n",
        "### Example in an IR System:\n",
        "\n",
        "1. **Without Stemming**:\n",
        "   - Search Query: \"fishing\"\n",
        "   - Result: No matches if documents only contain \"fish\"\n",
        "\n",
        "2. **With Stemming**:\n",
        "   - Search Query: \"fishing\" → Stemmed to \"fish\"\n",
        "   - Result: Documents containing \"fish\", \"fisher\", \"fishing\", etc., are all retrieved.\n",
        "\n",
        "### Practical Benefit:\n",
        "**Stemming** prevents users from experiencing incomplete search results due to simple word variations. It ensures the IR system understands the relationship between different forms of a word, ultimately improving the search experience.\n",
        "\n",
        "Your example highlights exactly why stemming is a cornerstone of effective IR systems!"
      ],
      "metadata": {
        "id": "ITb4eykVvVCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use nltk library and use stemmer algo that basically does stemming for us."
      ],
      "metadata": {
        "id": "OHA5g6AXvhuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porter Stemmer:\n",
        "The Porter Stemmer, introduced in 1980, is one of the most widely used stemming algorithms in text processing."
      ],
      "metadata": {
        "id": "5BL4KCNwxSjI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you want to try stemming on other languages you can use snow ball stemmer."
      ],
      "metadata": {
        "id": "VrAMwAg6xsKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "_puXpRQeul6Z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "words = [\"running\", \"runner\", \"ran\", \"runs\", \"easily\", \"fishing\"]\n",
        "\n",
        "for word in words:\n",
        "    print(f\"{word} -> {ps.stem(word)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOIKD5ZQuzeR",
        "outputId": "74b54624-e292-480a-c767-ac9e5fd462c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running -> run\n",
            "runner -> runner\n",
            "ran -> ran\n",
            "runs -> run\n",
            "easily -> easili\n",
            "fishing -> fish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "def stem_words(text):\n",
        "  for word in text.split():\n",
        "    return \"\".join(ps.stem(word))"
      ],
      "metadata": {
        "id": "4Bpr96Gty75R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"walk walking walks walked\"\n",
        "stem_words(sample)"
      ],
      "metadata": {
        "id": "7JuZRVkuzQtA",
        "outputId": "8aa57d22-cff1-4e52-cc27-25e8c43c1a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "def stem_words(text):\n",
        "    return \" \".join([ps.stem(word) for word in text.split()])"
      ],
      "metadata": {
        "id": "m1hjM6d8zi9J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample2 = \"walk walking walks walked\"\n",
        "stem_words(sample2)"
      ],
      "metadata": {
        "id": "ynyI9aBhzXnw",
        "outputId": "6e3e2ef4-d657-4c83-8dc3-a42bbfae65b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walk walk walk walk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'][3]"
      ],
      "metadata": {
        "id": "q_3n8pSWz3GR",
        "outputId": "f6d39006-1ca0-45b0-efb7-f05a901668f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stem_words(data['review'][3])"
      ],
      "metadata": {
        "id": "zbrDv0yv0GhI",
        "outputId": "3eb106fb-aa88-4adf-d094-5b27cf0f363b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"basic there' a famili where a littl boy (jake) think there' a zombi in hi closet & hi parent are fight all the time.<br /><br />thi movi is slower than a soap opera... and suddenly, jake decid to becom rambo and kill the zombie.<br /><br />ok, first of all when you'r go to make a film you must decid if it a thriller or a drama! as a drama the movi is watchable. parent are divorc & argu like in real life. and then we have jake with hi closet which total ruin all the film! i expect to see a boogeyman similar movie, and instead i watch a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well play parent & descent dialogs. as for the shot with jake: just ignor them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "he Problem Illustrated\n",
        "Consider a movie review text. Here is an example of where stemming might present issues:\n",
        "\n",
        "Original Words: \"running,\" \"better,\" \"flies\"\n",
        "Stemmed Forms:\n",
        "\"running\" → \"run\"\n",
        "\"better\" → \"better\" (Note: Some stemmers may return \"bet\")\n",
        "\"flies\" → \"fli\" (depending on the stemming algorithm used)\n",
        "This can lead to unexpected or less meaningful forms that do not capture the intended context of the word.\n",
        "\n",
        "Why Stemming Falls Short\n",
        "In a detailed review or context, simple stemming could lead to:\n",
        "\n",
        "\"running\" being reduced to \"run,\" which might change verb tense or intent.\n",
        "\"flies\" being reduced to \"fli,\" which loses meaning entirely (and creates ambiguity if \"fly\" was meant as an insect or as an action).\n",
        "\"better\" might remain unchanged or be stemmed incorrectly, especially with context-sensitive words like comparative adjectives.\n",
        "Advantages of Lemmatization\n",
        "Lemmatization, in contrast, analyzes words based on their meaning and context, converting them to their dictionary base form:\n",
        "\n",
        "\"running\" → \"run\" (maintains the correct verb form and context)\n",
        "\"flies\" → \"fly\" (correctly identifies the base word, whether as a noun or verb based on usage)\n",
        "\"better\" → \"good\" (correctly identifies it as a comparative form of \"good\")\n",
        "This approach ensures that words retain their contextual meaning, making it ideal for applications that require a deeper understanding of language."
      ],
      "metadata": {
        "id": "uAhXb0px1VEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization will always return you the correct english root form but it is bit slow compared to stemming because it search for the corect word."
      ],
      "metadata": {
        "id": "L3LSxroS2hnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you had to show user the output then use lemmatization if not n speed is concern then use stemming."
      ],
      "metadata": {
        "id": "AjuknVGx2uEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatizatioon unlie stemming reduces the inflected words properly to their root forms ensuring that the root word belongs to a particular language. here the root word is called lemma. that is the cannonical form of a set of words."
      ],
      "metadata": {
        "id": "xDtM7Qkw3Q3D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In lemmatization you basically go in the mapped dictinary to find words. such as WordNet is a lexical dictionary where you english language words how they are related are stored in this dictionary. reason it is bit slow beacuse it sreachers the right word here. and stemming uses algo to generate word so it is fast but less accurate."
      ],
      "metadata": {
        "id": "QBvc4G7R3myS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In lemmatization, words are reduced to their base or root form (known as a lemma) by consulting a lexical dictionary that stores detailed word forms and their relationships. This differs from stemming, which merely trims word endings based on simple rules without considering meaning or context.\n",
        "\n",
        "WordNet: A Key Resource for Lemmatization\n",
        "A prime example of such a lexical resource is WordNet, a large, freely available English lexical database often used for lemmatization in NLP. In WordNet:\n",
        "\n",
        "Words are grouped into synsets (sets of synonyms), representing different senses or meanings.\n",
        "Each word form is connected to its base form through complex mappings that account for parts of speech, meaning, and grammatical context.\n",
        "For example:\n",
        "\n",
        "\"better\" would be mapped to \"good\" (adjective) when used as a comparative form, thanks to WordNet’s understanding of English grammar rules.\n",
        "\"ran\" would be lemmatized to \"run\" as a verb.\n",
        "By using such a dictionary, lemmatization ensures that the transformation of words maintains grammatical and contextual integrity, making it a more precise approach than stemming for many text processing applications. This is especially useful for tasks like text summarization, information retrieval, and sentiment analysis, where preserving word meanings and relationships is crucial."
      ],
      "metadata": {
        "id": "Ax5CEG6w4JEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Initialize the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Example words\n",
        "words = [\"running\", \"better\", \"flies\", \"children\", \"went\"]\n",
        "\n",
        "# Lemmatize words with context (parts of speech)\n",
        "print(\"Lemmatized words:\")\n",
        "for word in words:\n",
        "    lemma = lemmatizer.lemmatize(word)\n",
        "    print(f\"{word} -> {lemma}\")\n",
        "\n",
        "# To lemmatize more accurately, you can specify parts of speech (e.g., verb, noun)\n",
        "print(\"\\nLemmatized with POS context:\")\n",
        "print(f\"running (verb) -> {lemmatizer.lemmatize('running', pos='v')}\")\n",
        "print(f\"better (adj) -> {lemmatizer.lemmatize('better', pos='a')}\")\n",
        "print(f\"flies (noun) -> {lemmatizer.lemmatize('flies', pos='n')}\")\n"
      ],
      "metadata": {
        "id": "1s1E_iQ10Llc",
        "outputId": "76b1a50d-debc-48e2-a6a7-572685b3a181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized words:\n",
            "running -> running\n",
            "better -> better\n",
            "flies -> fly\n",
            "children -> child\n",
            "went -> went\n",
            "\n",
            "Lemmatized with POS context:\n",
            "running (verb) -> run\n",
            "better (adj) -> good\n",
            "flies (noun) -> fly\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}